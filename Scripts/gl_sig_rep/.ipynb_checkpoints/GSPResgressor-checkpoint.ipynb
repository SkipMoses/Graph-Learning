{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c472fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy_groupies as npg\n",
    "import scipy.sparse as sps\n",
    "import numpy.matlib as npm\n",
    "import cvxpy as cp\n",
    "import scipy.io\n",
    "import networkx as nx\n",
    "import graph_learning_gaussian as glg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720ed38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_learning_gaussian_regressor(X_noisy, param):\n",
    "    \n",
    "    N = param['N']\n",
    "    max_iter = param['max_iter']\n",
    "    alpha = param['alpha']\n",
    "    beta = param['beta']\n",
    "\n",
    "    objective = [0]*max_iter\n",
    "    Y_0 = X_noisy\n",
    "    Y = Y_0\n",
    "    R = np.zeros(Y.shape)\n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        # Step 1: given Y and R, update L\n",
    "        # This is the same as Step 1 of Dong's algorithm\n",
    "        # with Y = Y-R\n",
    "        L = glg.optimize_laplacian_gaussian(N,(Y-R),alpha,beta)\n",
    "        \n",
    "        # Step 2: given L and R, update Y\n",
    "        # Note if we expand the quadratic form \n",
    "        # we get a constant term with L and R, so\n",
    "        # the optimization is identical to Dong's second\n",
    "        # Step.\n",
    "        temp = np.linalg.cholesky(np.identity(N) + alpha*L)\n",
    "        temp_t = np.transpose(temp)\n",
    "        arg1 = np.linalg.lstsq(temp_R, Y_0)[0]\n",
    "        print('arg1 shape is ' + str(arg1.shape))\n",
    "        print('R shape is ' + str(temp.shape))\n",
    "        Y = np.linalg.lstsq(temp, arg1)[0]\n",
    "        \n",
    "        # Step 3: Given L and Y, update R\n",
    "        R_var = cp.Variable(Y.shape)\n",
    "        obj = alpha*cp.norm(cp.quad_form(R_var,L), \"fro\")\n",
    "        prob3 = cp.Problem(obj, [])\n",
    "        prob3.solve()\n",
    "        R = R_var.value()\n",
    "        # Store objective\n",
    "        arg1 = np.linalg.norm(Y-Y_0, 'fro')**2 \n",
    "        arg2 = alpha*(np.transpose((Y@np.transpose(Y)).flatten('F'))@(L.flatten('F')))\n",
    "        arg3 = beta*np.linalg.norm(L, 'fro')**2\n",
    "        objective[i] = arg1 + arg2 + arg3\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if i>=2 and abs(objective(i) - objective(i-1)) < 10**(-4):\n",
    "            print(str(i) + ' iterations needed to converge.')\n",
    "            break\n",
    "        return([L.round(4), Y.round(4), R.round(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe12c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_hat = cp.Variable((N,N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
