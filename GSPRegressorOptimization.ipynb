{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70478561",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygsp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15544/1769192906.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpygsp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygsp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from pygsp import graphs, filters\n",
    "from numpy.linalg import inv\n",
    "import networkx as nx\n",
    "import random as rand\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "%run SyntheticDataGenerator.py\n",
    "%run DongsAlgorithm.py\n",
    "%run Metrics.py\n",
    "%run Scripts/GSPRegression.py\n",
    "\n",
    "# For reproducing results \n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ebdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.erdos_renyi_graph(20, 0.2, seed = 7)\n",
    "S1 = RandomSignal(G, 100, 0, .5, 0)\n",
    "L_ER = nx.laplacian_matrix(G).toarray()\n",
    "normL_ER = (L_ER.shape[0]/np.trace(L_ER))*L_ER\n",
    "E = GL_SigRep(0.002, .9, S1, .001, 100)\n",
    "ComputeMetrics(E, normL_ER, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obser = 20\n",
    "num_trials = 5\n",
    "dist_vec = ['uniform', 'normal', 'binomial']\n",
    "param_vec = [['0,1'], ['0,.5', '0,.5'], ['1,.5']]\n",
    "M = generate_trials(num_obser, num_trials, dist_vec, param_vec, seed)\n",
    "b = np.ones(4)\n",
    "S2 = RandomRegressorSignal(G, 0, .5, b, M, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal hyperparamerters for signal w/o regressors\n",
    "E = GL_SigRep(0.002, .9, S2, .001, 100)\n",
    "ComputeMetrics(E, normL_ER, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af796c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters optimized by first optimizing a, and then optimizing b.\n",
    "a = 0.001\n",
    "b = 0.14040404040404042\n",
    "Etemp = GL_SigRep(a, b, S2, .001, 100) \n",
    "ComputeMetrics(Etemp, normL_ER, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters optimized by alternating optimization\n",
    "a = 0.001106060606060606\n",
    "b = 0.49949494949494955\n",
    "Etemp = GL_SigRep(a, b, S2, .001, 100) \n",
    "ComputeMetrics(Etemp, normL_ER, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0092\n",
    "b = 1\n",
    "Etemp = GSP_Regression(a, b, S2, M, .001, 100)[0]\n",
    "ComputeMetrics(Etemp, normL_ER, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.001106060606060606\n",
    "b = 0.49949494949494955\n",
    "ratio = np.linspace(0.45, 0.55, 100)\n",
    "LGs = [GL_SigRep(a, r, S2, .001, 100) for r in ratio]  \n",
    "Metrics = [ComputeMetrics(e, normL_ER, .01) for e in LGs]\n",
    "fmes = [i['F-Measure'] for i in Metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65723d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Optimize a\n",
    "#(.001, 1, 100) fmes = 0.42152466367713 a = .001\n",
    "#(.0001, .0015, 100) fmes = 0.44554455445544555 a = 0.001\n",
    "\n",
    "# Optimize b\n",
    "#(.5, 1.5, 100) fmes = 0.4568527918781726 b = 0.5\n",
    "#(.1, .9, 100) fmes = 0.5 b = 0.14040404040404042\n",
    "\n",
    "# Optimize a\n",
    "#(.0005, .0015, 100) fmes = .5 a = 0.001, b = 0.14040404040404042\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Optimize with alternating \n",
    "\n",
    "# b = 1\n",
    "#(.001, 1, 100) fmes = 0.42152466367713 a = .001\n",
    "\n",
    "# a = 0.001\n",
    "#(.5, 1.5, 100) fmes = 0.4568527918781726, b = 0.5\n",
    "\n",
    "# b = 0.5\n",
    "#(0.0005, 0.0015, 100) fmes = 0.46391752577319584, a = 0.001106060606060606\n",
    "\n",
    "# a = 0.001106060606060606 \n",
    "#(0.45, 0.55, 100) fmes = 0.46391752577319584, b = 0.49949494949494955 \n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Optimize Precision\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "for i in range(len(fmes)):\n",
    "    print(i, fmes[i], ratio[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49d0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0092\n",
    "b = 0.49949494949494955\n",
    "ratio = np.linspace(0.01, 2.1, 100)\n",
    "LGs = [GSP_Regression(a, r, S2, M, .001, 100)[0] for r in ratio]  \n",
    "Metrics = [ComputeMetrics(e, normL_ER, .01) for e in LGs]\n",
    "fmes = [i['F-Measure'] for i in Metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d8904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = 1\n",
    "#(0.1, 1.1, 100) fmes = 0.26666666666666666, a = 0.1101010101010101, 0.22121212121212122 <- This is strange,\n",
    "# Why did this work!\n",
    "#(.001, .2, 100) # ERROR 'list' object has no attribute 'transpose' line 55\n",
    "#(.009, .2, 100) # ERROR \"\"\n",
    "# Error is an issue with how regression coefficents are being recoverd.\n",
    "# Removing this and proceeding.\n",
    "\n",
    "#(.01, 2, 100) ERROR: invalid index to scalar variable.\n",
    "# For some reason the return statement when threshold was met was not working as intended.\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "# b = 1\n",
    "# (.01, 2, 100) fmes = 0.4406779661016949, a = 0.01\n",
    "# (0.05, .15, 100) Seems like a poor way to optimize\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "# a = 0.01, b = 1\n",
    "# (.5, 1.5, 100) No good\n",
    "# (.001, 10, 100) fmes = 0.42152466367713, a = 0.001\n",
    "# (0.0001, 0.01, 100) fmes = 0.4761904761904762 a = 0.0092 \n",
    "# (0.009, 0.0093, 100) fmes = 0.4761904761904762 a = 0.0092\n",
    "\n",
    "# a = 0.0092\n",
    "# (0.01, 2.1, 100) fmes = 0.4761904761904762 a = 1.0022222222222223\n",
    "for i in range(len(fmes)):\n",
    "    print(i, fmes[i], ratio[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe38728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason only the first pass learned a laplacian.\n",
    "for e in LGs:\n",
    "    print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ff02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GSP_Regression_test(a, b, Signal, P, tol, max_itr):\n",
    "    print(\"Begining GSP Regression:\")\n",
    "    Y = Signal\n",
    "    print(\"Initial shape of Y \" + str(Y.shape))\n",
    "    R = np.zeros(Y.shape)\n",
    "    print(\"Initial shape of R \" + str(R.shape))\n",
    "    I = np.matrix(np.identity(Signal.shape[0]))\n",
    "    L = Problem1(a, b, Y)\n",
    "    print(\"Initial shape of L \" + str(L.shape))\n",
    "    for i in range(1,max_itr):\n",
    "        print(\"___________________________________________________________________\")\n",
    "        print(str(i) + \" pass\")\n",
    "        temp = L\n",
    "        print(\"Current shape of L is \" + str(L.shape) + \" Learing Y.\")\n",
    "        # Closed form solution given by Dong et al.\n",
    "        Y = (inv(I + a*L))@(Signal - R)\n",
    "        print(\"Current shape of Y is \" + str(Y.shape) + \" Learning R.\")\n",
    "        # Find new Regressor matrix\n",
    "        R = Signal - Y\n",
    "        print(\"Current shape of R is \" + str(R.shape) + \" Learning L.\")\n",
    "        # Find a new L given Y.\n",
    "        L = Problem1(a, b, Y)\n",
    "        print(\"Shape of learning L is \" + str(L.shape) + \" Finished iteration\")\n",
    "        # Check if we are within the tolerance\n",
    "        if(np.all(abs(temp - L) < tol)):\n",
    "                print(\"Tolerance met.\")\n",
    "                return np.asarray(L)\n",
    "        print(\"Tolerance not met.\")\n",
    "    #b = (inv(P.transpose()@P)@P.transpose)@np.matrix.flatten(R, 'F')\n",
    "    #return [np.asarray(L), Y, b]\n",
    "    print(\"Max numeber of iterations reached.\")\n",
    "    return [np.asarray(L), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd003891",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = GSP_Regression_test2(.01, 1, S2, M, .001, 100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "E[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = GSP_Regression_test2(.01, 1, S2, M, .001, 100)[0]\n",
    "ComputeMetrics(E, normL_ER, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "E[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb847e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GSP_Regression_test2(a, b, Signal, P, tol, max_itr):\n",
    "    print(\"Begining GSP Regression:\")\n",
    "    Y = Signal\n",
    "    print(\"Initial shape of Y \" + str(Y.shape))\n",
    "    R = np.zeros(Y.shape)\n",
    "    print(\"Initial shape of R \" + str(R.shape))\n",
    "    I = np.matrix(np.identity(Signal.shape[0]))\n",
    "    L = Problem1(a, b, Y)\n",
    "    print(\"Initial shape of L \" + str(L.shape))\n",
    "    for i in range(1,max_itr):\n",
    "        print(\"___________________________________________________________________\")\n",
    "        print(str(i) + \" pass\")\n",
    "        temp = L\n",
    "        print(\"Current shape of L is \" + str(L.shape) + \" Learing Y.\")\n",
    "        # Closed form solution given by Dong et al.\n",
    "        Y = (inv(I + a*L))@(Signal - R)\n",
    "        print(\"Current shape of Y is \" + str(Y.shape) + \" Learning R.\")\n",
    "        # Find new Regressor matrix\n",
    "        R = Signal - Y\n",
    "        print(\"Current shape of R is \" + str(R.shape) + \" Learning L.\")\n",
    "        # Find a new L given Y.\n",
    "        L = Problem1(a, b, Y)\n",
    "        print(\"Shape of learning L is \" + str(L.shape) + \" Finished iteration\")\n",
    "        # Check if we are within the tolerance\n",
    "        if(np.all(abs(temp - L) < tol)):\n",
    "                print(\"Tolerance met.\")\n",
    "                break\n",
    "        print(\"Tolerance not met.\")\n",
    "    #b = (inv(P.transpose()@P)@P.transpose)@np.matrix.flatten(R, 'F')\n",
    "    #return [np.asarray(L), Y, b]\n",
    "    print(\"Max numeber of iterations reached.\")\n",
    "    return [np.asarray(L), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67291c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
